import os
import openai
from flask import Flask, jsonify, request

app = Flask(__name__)

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ API Key ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏°‡∏≤‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
openai.api_key = os.getenv("OPENAI_API_KEY")
print("üîë Loaded API Key:", openai.api_key)  # ‡∏î‡∏π‡∏ß‡πà‡∏≤ API Key ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏î‡πâ‡πÑ‡∏´‡∏°

@app.route('/generate_prompt/<category>', methods=['GET'])
def generate_prompt(category):
    print(f"üì¢ Received request for category: {category}")  # Debug Request

    try:
        response = openai.ChatCompletion.create(
            model="gpt-4-turbo",
            messages=[
                {"role": "system", "content": "You are an expert in generating AI video prompts."},
                {"role": "user", "content": f"Generate a detailed AI video prompt for {category}."}
            ],
            max_tokens=200
        )
        return jsonify({"prompt": response['choices'][0]['message']['content']})
    
    except Exception as e:
        print("‚ùå Error:", str(e))  # ‡∏î‡∏π‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡∏¥‡∏î Error ‡∏≠‡∏∞‡πÑ‡∏£
        return jsonify({"error": str(e)}), 500  # ‡∏™‡πà‡∏á Error Response ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
